{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# QUASI-RECURRENT NEURAL NETWORKS\n",
    "- https://arxiv.org/abs/1611.01576"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN\n",
    "<img src=\"https://t1.daumcdn.net/thumb/R1280x0/?fname=http://t1.daumcdn.net/brunch/service/user/IgT/image/0KQEHorp3Mpiwo5H9zQpeMQv4SE.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __RNN(LSTM)__ have become the standard model architecture for deep learning __approaches to sequence modeling tasks.__\n",
    "- RNN(LSTM)설명 : https://brunch.co.kr/@chris-song/9\n",
    "- RNNs repeatedly apply a function with trainable parameters to a hidden state. \n",
    "- RNN applications in the natural language domain range from sentence classification to word- and character-level language modeling. \n",
    "- RNNs are also commonly the basic building block for more complex models for tasks such as machine translation or question answering. \n",
    "- Unfortunately standard RNNs, including LSTMs, are limited in their capability to handle tasks involving very long sequences, such as document classification or character-level machine translation, as the computation of features or states for different parts of the document cannot occur in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN\n",
    "<img src=\"http://i.stack.imgur.com/HyAs5.png\">\n",
    "- more popular on tasks involving image data, have also been applied to sequence encoding tasks.\n",
    "- Such models apply time-invariant filter functions in parallel to windows along the input sequence. \n",
    "- CNNs possess several advantages over recurrent models, including increased parallelism and better scaling to long sequences such as those often seen with character-level language data. \n",
    "- Convolutional models for sequence processing have been more successful when combined with RNN layers in a hybrid architecture (Lee et al., 2016), because traditional max- and average-pooling approaches to combining convolutional features across timesteps assume time invariance and hence cannot make full use of large-scale sequence order information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We present quasi-recurrent neural networks for neural sequence modeling. \n",
    "- QRNNs address both drawbacks of standard models: \n",
    "    - __Like CNNs,__ QRNNs allow for parallel computation across both timestep and minibatch dimensions, enabling high throughput and good scaling to long sequences. \n",
    "    - __Like RNNs,__ QRNNs allow the output to depend on the overall order of elements in the sequence. \n",
    "- We describe QRNN variants tailored to several natural language tasks, including document-level sentiment classification, language modeling, and character-level machine translation. These models outperform strong LSTM baselines on all three tasks while dramatically reducing computation time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://metamind.io/images/qrnn_block.svg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Model\n",
    "- https://theneuralperspective.com/2016/12/16/quasi-recurrent-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import functools\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "from matplotlib import pylab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DESCR': \"Optical Recognition of Handwritten Digits Data Set\\n===================================================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttp://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\nReferences\\n----------\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\",\n",
       " 'data': array([[  0.,   0.,   5., ...,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0., ...,  10.,   0.,   0.],\n",
       "        [  0.,   0.,   0., ...,  16.,   9.,   0.],\n",
       "        ..., \n",
       "        [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
       "        [  0.,   0.,   2., ...,  12.,   0.,   0.],\n",
       "        [  0.,   0.,  10., ...,  12.,   1.,   0.]]),\n",
       " 'images': array([[[  0.,   0.,   5., ...,   1.,   0.,   0.],\n",
       "         [  0.,   0.,  13., ...,  15.,   5.,   0.],\n",
       "         [  0.,   3.,  15., ...,  11.,   8.,   0.],\n",
       "         ..., \n",
       "         [  0.,   4.,  11., ...,  12.,   7.,   0.],\n",
       "         [  0.,   2.,  14., ...,  12.,   0.,   0.],\n",
       "         [  0.,   0.,   6., ...,   0.,   0.,   0.]],\n",
       " \n",
       "        [[  0.,   0.,   0., ...,   5.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   9.,   0.,   0.],\n",
       "         [  0.,   0.,   3., ...,   6.,   0.,   0.],\n",
       "         ..., \n",
       "         [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
       "         [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,  10.,   0.,   0.]],\n",
       " \n",
       "        [[  0.,   0.,   0., ...,  12.,   0.,   0.],\n",
       "         [  0.,   0.,   3., ...,  14.,   0.,   0.],\n",
       "         [  0.,   0.,   8., ...,  16.,   0.,   0.],\n",
       "         ..., \n",
       "         [  0.,   9.,  16., ...,   0.,   0.,   0.],\n",
       "         [  0.,   3.,  13., ...,  11.,   5.,   0.],\n",
       "         [  0.,   0.,   0., ...,  16.,   9.,   0.]],\n",
       " \n",
       "        ..., \n",
       "        [[  0.,   0.,   1., ...,   1.,   0.,   0.],\n",
       "         [  0.,   0.,  13., ...,   2.,   1.,   0.],\n",
       "         [  0.,   0.,  16., ...,  16.,   5.,   0.],\n",
       "         ..., \n",
       "         [  0.,   0.,  16., ...,  15.,   0.,   0.],\n",
       "         [  0.,   0.,  15., ...,  16.,   0.,   0.],\n",
       "         [  0.,   0.,   2., ...,   6.,   0.,   0.]],\n",
       " \n",
       "        [[  0.,   0.,   2., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,  14., ...,  15.,   1.,   0.],\n",
       "         [  0.,   4.,  16., ...,  16.,   7.,   0.],\n",
       "         ..., \n",
       "         [  0.,   0.,   0., ...,  16.,   2.,   0.],\n",
       "         [  0.,   0.,   4., ...,  16.,   2.,   0.],\n",
       "         [  0.,   0.,   5., ...,  12.,   0.,   0.]],\n",
       " \n",
       "        [[  0.,   0.,  10., ...,   1.,   0.,   0.],\n",
       "         [  0.,   2.,  16., ...,   1.,   0.,   0.],\n",
       "         [  0.,   0.,  15., ...,  15.,   0.,   0.],\n",
       "         ..., \n",
       "         [  0.,   4.,  16., ...,  16.,   6.,   0.],\n",
       "         [  0.,   8.,  16., ...,  16.,   8.,   0.],\n",
       "         [  0.,   1.,   8., ...,  12.,   1.,   0.]]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optical Recognition of Handwritten Digits Data Set\n",
      "===================================================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      "References\n",
      "----------\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 8, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   7.,  15.,  13.,   1.,   0.,   0.],\n",
       "       [  0.,   8.,  13.,   6.,  15.,   4.,   0.,   0.],\n",
       "       [  0.,   2.,   1.,  13.,  13.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   2.,  15.,  11.,   1.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   1.,  12.,  12.,   1.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   1.,  10.,   8.,   0.],\n",
       "       [  0.,   0.,   8.,   4.,   5.,  14.,   9.,   0.],\n",
       "       [  0.,   0.,   7.,  13.,  13.,   9.,   0.,   0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1144077b8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPcAAAD7CAYAAAC2TgIoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/weNbqyzvNMH3AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1147fb1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.imshow(digits.images[3], cmap=pylab.cm.gray_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_by_digits(graph, qrnn=-1, baseline=False, random=False):\n",
    "    digits = load_digits()\n",
    "    horizon, vertical, n_class = (8, 8, 10)  # 8 x 8 image, 0~9 number(=10 class)\n",
    "    size = 128  # state vector size\n",
    "    batch_size = 128\n",
    "    images = digits.images / np.max(digits.images)  # simple normalization\n",
    "    target = np.array([[1 if t == i else 0 for i in range(n_class)] for t in digits.target])  # to 1 hot vector\n",
    "    learning_rate = 0.001\n",
    "    train_iter = 1000\n",
    "    summary_dir = os.path.join(os.getcwd(), \"./summary\")\n",
    "\n",
    "    with tf.name_scope(\"placeholder\"):\n",
    "        X = tf.placeholder(tf.float32, [batch_size, vertical, horizon])\n",
    "        y = tf.placeholder(tf.float32, [batch_size, n_class])\n",
    "\n",
    "    # 예측값 pred를 아래 3가지 경우에 따라서 구함.\n",
    "    if qrnn > 0:\n",
    "        pred = qrnn_forward(X, size, n_class, batch_size, conv_size=qrnn)\n",
    "        summary_dir += \"/qrnn\"\n",
    "    elif baseline:\n",
    "        pred = baseline_forward(X, size, n_class)\n",
    "        summary_dir += \"/lstm\"\n",
    "    else:\n",
    "        pred = random_forward(X, size, n_class)            \n",
    "        summary_dir += \"/random\"\n",
    "\n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "    with tf.name_scope(\"evaluation\"):\n",
    "        correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "    with tf.name_scope(\"summary\"):\n",
    "        tf.summary.scalar(\"loss\", loss)\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)\n",
    "        merged = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(summary_dir, graph)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in range(train_iter):\n",
    "            indices = np.random.randint(len(digits.target) - batch_size, size=batch_size) # 0부터 1797-128중에서의 random int 128개   \n",
    "            _X = images[indices]\n",
    "            _y = target[indices]\n",
    "            sess.run(optimizer, feed_dict={X: _X, y: _y})\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                _loss, _accuracy, _merged = sess.run([loss, accuracy, merged], feed_dict={X: _X, y: _y})\n",
    "                writer.add_summary(_merged, i)\n",
    "                print(\"Iter {}: loss={}, accuracy={}\".format(i, _loss, _accuracy))\n",
    "\n",
    "        with tf.name_scope(\"test-evaluation\"):\n",
    "            acc = sess.run(accuracy, feed_dict={X: images[-batch_size:], y: target[-batch_size:]})\n",
    "            print(\"Testset Accuracy={}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Random forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_forward(X, size, n_class):\n",
    "    batch_size = int(X.get_shape()[0])\n",
    "\n",
    "    with tf.name_scope(\"Random-Classifier\"):\n",
    "        rand_vector = tf.random_normal([batch_size, size])  # batch_size x size random vector\n",
    "        W = tf.Variable(tf.random_normal([size, n_class]), name=\"W\")\n",
    "        b = tf.Variable(tf.random_normal([n_class]), name=\"b\")\n",
    "        output = tf.matmul(rand_vector, W) + b\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_forward(X, size, n_class):\n",
    "    shape = X.get_shape()\n",
    "    _X = tf.transpose(X, [1, 0, 2])  # batch_size x sentence_length x word_length -> batch_size x sentence_length x word_length\n",
    "    _X = tf.reshape(_X, [-1, int(shape[2])])  # (batch_size x sentence_length) x word_length\n",
    "    seq = tf.split(0, int(shape[1]), _X)  # sentence_length x (batch_size x word_length)\n",
    "\n",
    "    with tf.name_scope(\"LSTM\"):\n",
    "        lstm_cell = rnn_cell.BasicLSTMCell(size, forget_bias=1.0)\n",
    "        outputs, states = rnn.rnn(lstm_cell, seq, dtype=tf.float32)\n",
    "\n",
    "    with tf.name_scope(\"LSTM-Classifier\"):\n",
    "        W = tf.Variable(tf.random_normal([size, n_class]), name=\"W\")\n",
    "        b = tf.Variable(tf.random_normal([n_class]), name=\"b\")\n",
    "        output = tf.matmul(outputs[-1], W) + b\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QRNN forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def qrnn_forward(X, size, n_class, batch_size, conv_size):\n",
    "    in_size = int(X.get_shape()[2])\n",
    "\n",
    "    qrnn = QRNN(in_size=in_size, size=size, conv_size=conv_size)\n",
    "    hidden = qrnn.forward(X)\n",
    "\n",
    "    with tf.name_scope(\"QRNN-Classifier\"):\n",
    "        W = tf.Variable(tf.random_normal([size, n_class]), name=\"W\")\n",
    "        b = tf.Variable(tf.random_normal([n_class]), name=\"b\")\n",
    "        output = tf.add(tf.matmul(hidden, W), b)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_random():\n",
    "    print(\"Random Working check\")\n",
    "    with tf.Graph().as_default() as random:\n",
    "        check_by_digits(random, random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Working check\n",
      "Iter 0: loss=17.487810134887695, accuracy=0.09375\n",
      "Iter 100: loss=19.236494064331055, accuracy=0.1015625\n",
      "Iter 200: loss=16.416854858398438, accuracy=0.078125\n",
      "Iter 300: loss=15.105697631835938, accuracy=0.078125\n",
      "Iter 400: loss=15.88584041595459, accuracy=0.1015625\n",
      "Iter 500: loss=14.164024353027344, accuracy=0.09375\n",
      "Iter 600: loss=15.28477668762207, accuracy=0.0703125\n",
      "Iter 700: loss=13.537178039550781, accuracy=0.125\n",
      "Iter 800: loss=12.486244201660156, accuracy=0.1484375\n",
      "Iter 900: loss=11.974689483642578, accuracy=0.078125\n",
      "Testset Accuracy=0.109375\n",
      "CPU times: user 2.03 s, sys: 205 ms, total: 2.24 s\n",
      "Wall time: 1.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_baseline():\n",
    "    print(\"Baseline(LSTM) Working check\")\n",
    "    with tf.Graph().as_default() as baseline:\n",
    "        check_by_digits(baseline, baseline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline(LSTM) Working check\n",
      "Iter 0: loss=2.405916452407837, accuracy=0.1328125\n",
      "Iter 100: loss=0.35039275884628296, accuracy=0.9140625\n",
      "Iter 200: loss=0.2035084068775177, accuracy=0.9296875\n",
      "Iter 300: loss=0.05401304364204407, accuracy=0.9765625\n",
      "Iter 400: loss=0.021765559911727905, accuracy=1.0\n",
      "Iter 500: loss=0.015437640249729156, accuracy=1.0\n",
      "Iter 600: loss=0.028048399835824966, accuracy=1.0\n",
      "Iter 700: loss=0.02051163837313652, accuracy=1.0\n",
      "Iter 800: loss=0.004900586325675249, accuracy=1.0\n",
      "Iter 900: loss=0.009282441809773445, accuracy=1.0\n",
      "Testset Accuracy=0.9453125\n",
      "CPU times: user 56.7 s, sys: 3 s, total: 59.7 s\n",
      "Wall time: 25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QRNN():\n",
    "    def __init__(self, in_size, size, conv_size=2):\n",
    "        self.kernel = None\n",
    "        self.batch_size = -1\n",
    "        self.conv_size = conv_size\n",
    "        self.c = None\n",
    "        self.h = None\n",
    "        self._x = None\n",
    "        if conv_size == 1:\n",
    "            self.kernel = QRNNLinear(in_size, size)\n",
    "        elif conv_size == 2:\n",
    "            self.kernel = QRNNWithPrevious(in_size, size)\n",
    "        else:\n",
    "            self.kernel = QRNNConvolution(in_size, size, conv_size)\n",
    "\n",
    "    def _step(self, f, z, o):\n",
    "        with tf.variable_scope(\"fo-Pool\"):\n",
    "            # f,z,o is batch_size x size\n",
    "            f = tf.sigmoid(f)\n",
    "            z = tf.tanh(z)\n",
    "            o = tf.sigmoid(o)\n",
    "            self.c = tf.mul(f, self.c) + tf.mul(1 - f, z)\n",
    "            self.h = tf.mul(o, self.c)  # h is size vector\n",
    "\n",
    "        return self.h\n",
    "\n",
    "    def forward(self, x):\n",
    "        length = lambda mx: int(mx.get_shape()[0])\n",
    "\n",
    "        with tf.variable_scope(\"QRNN/Forward\"):\n",
    "            if self.c is None:\n",
    "                # init context cell\n",
    "                self.c = tf.zeros([length(x), self.kernel.size], dtype=tf.float32)\n",
    "\n",
    "            if self.conv_size <= 2:\n",
    "                # x is batch_size x sentence_length x word_length\n",
    "                # -> now, transpose it to sentence_length x batch_size x word_length\n",
    "                _x = tf.transpose(x, [1, 0, 2])\n",
    "\n",
    "                for i in range(length(_x)):\n",
    "                    t = _x[i] # t is batch_size x word_length matrix\n",
    "                    f, z, o = self.kernel.forward(t)\n",
    "                    self._step(f, z, o)\n",
    "            else:\n",
    "                c_f, c_z, c_o = self.kernel.conv(x)\n",
    "                for i in range(length(c_f)):\n",
    "                    f, z, o = c_f[i], c_z[i], c_o[i]\n",
    "                    self._step(f, z, o)\n",
    "\n",
    "        return self.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QRNNLinear():\n",
    "    def __init__(self, in_size, size):\n",
    "        self.in_size = in_size\n",
    "        self.size = size\n",
    "        self._weight_size = self.size * 3  # z, f, o\n",
    "        with tf.variable_scope(\"QRNN/Variable/Linear\"):\n",
    "            initializer = tf.random_normal_initializer()\n",
    "            self.W = tf.get_variable(\"W\", [self.in_size, self._weight_size], initializer=initializer)\n",
    "            self.b = tf.get_variable(\"b\", [self._weight_size], initializer=initializer)\n",
    "\n",
    "    def forward(self, t):\n",
    "        # x is batch_size x word_length matrix\n",
    "        _weighted = tf.matmul(t, self.W)\n",
    "        _weighted = tf.add(_weighted, self.b)\n",
    "\n",
    "        # now, _weighted is batch_size x weight_size\n",
    "        f, z, o = tf.split(1, 3, _weighted)  # split to f, z, o. each matrix is batch_size x size\n",
    "        return f, z, o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QRNNWithPrevious():\n",
    "\n",
    "    def __init__(self, in_size, size):\n",
    "        self.in_size = in_size\n",
    "        self.size = size\n",
    "        self._weight_size = self.size * 3  # z, f, o\n",
    "        self._previous = None\n",
    "        with tf.variable_scope(\"QRNN/Variable/WithPrevious\"):\n",
    "            initializer = tf.random_normal_initializer()\n",
    "            self.W = tf.get_variable(\"W\", [self.in_size, self._weight_size], initializer=initializer)\n",
    "            self.V = tf.get_variable(\"V\", [self.in_size, self._weight_size], initializer=initializer)\n",
    "            self.b = tf.get_variable(\"b\", [self._weight_size], initializer=initializer)\n",
    "\n",
    "    def forward(self, t):\n",
    "        if self._previous is None:\n",
    "            self._previous = tf.get_variable(\"previous\", [t.get_shape()[0], self.in_size], initializer=tf.random_normal_initializer())\n",
    "\n",
    "        _current = tf.matmul(t, self.W)\n",
    "        _previous = tf.matmul(self._previous, self.V)\n",
    "        _previous = tf.add(_previous, self.b)\n",
    "        _weighted = tf.add(_current, _previous)\n",
    "\n",
    "        f, z, o = tf.split(1, 3, _weighted)  # split to f, z, o. each matrix is batch_size x size\n",
    "        self._previous = t\n",
    "        return f, z, o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QRNNConvolution():\n",
    "\n",
    "    def __init__(self, in_size, size, conv_size):\n",
    "        self.in_size = in_size\n",
    "        self.size = size\n",
    "        self.conv_size = conv_size\n",
    "        self._weight_size = self.size * 3  # z, f, o\n",
    "\n",
    "        with tf.variable_scope(\"QRNN/Variable/Convolution\"):\n",
    "            initializer = tf.random_normal_initializer()\n",
    "            self.conv_filter = tf.get_variable(\"conv_filter\", [conv_size, in_size, self._weight_size], initializer=initializer)\n",
    "\n",
    "    def conv(self, x):\n",
    "        # !! x is batch_size x sentence_length x word_length(=channel) !!\n",
    "        _weighted = tf.nn.conv1d(x, self.conv_filter, stride=1, padding=\"SAME\", data_format=\"NHWC\")\n",
    "\n",
    "        # _weighted is batch_size x conved_size x output_channel\n",
    "        _w = tf.transpose(_weighted, [1, 0, 2])  # conved_size x  batch_size x output_channel\n",
    "        _ws = tf.split(2, 3, _w) # make 3(f, z, o) conved_size x  batch_size x size\n",
    "        return _ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.nn.conv1d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_qrnn():\n",
    "    print(\"QRNN Working check\")\n",
    "    with tf.Graph().as_default() as qrnn:\n",
    "        check_by_digits(qrnn, qrnn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QRNN Working check\n",
      "Iter 0: loss=7.124448299407959, accuracy=0.0390625\n",
      "Iter 100: loss=1.197694182395935, accuracy=0.6640625\n",
      "Iter 200: loss=0.4061892628669739, accuracy=0.8671875\n",
      "Iter 300: loss=0.1676613986492157, accuracy=0.9453125\n",
      "Iter 400: loss=0.10967914760112762, accuracy=0.96875\n",
      "Iter 500: loss=0.08891242742538452, accuracy=0.9765625\n",
      "Iter 600: loss=0.05394919961690903, accuracy=0.9765625\n",
      "Iter 700: loss=0.027798496186733246, accuracy=1.0\n",
      "Iter 800: loss=0.024984735995531082, accuracy=1.0\n",
      "Iter 900: loss=0.009005965664982796, accuracy=1.0\n",
      "Testset Accuracy=0.9296875\n",
      "CPU times: user 1min 13s, sys: 6.7 s, total: 1min 20s\n",
      "Wall time: 26.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_qrnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
