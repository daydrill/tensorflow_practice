{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3_텐서플로우 기본"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple model\n",
    "<img src=\"./img/simple.jpeg\" width=50%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant(5, name=\"imput_a\")\n",
    "b = tf.constant(3, name=\"imput_b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = tf.multiply(a,b, name=\"mul_c\")\n",
    "d = tf.add(a,b, name=\"add_d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = tf.add(c,d, name=\"add_e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 개선사항\n",
    "- 입력은 tf.constant 노드 대신에 __플레이스홀더를 사용.__\n",
    "- 두개의 이산 스칼라(discrete scalar) 입력 대신에 __가변 길이의 하나의 벡터 사용.__\n",
    "- 그래프를 사용하는 동안의 시간에 따른 __모든 출력값을 누적.__\n",
    "- 그래프를 __namescope__로 깔끔하게 분할.\n",
    "- 각각의 실행 후에 그래프의 출력, 모든 출력 결과의 누적, 모든 출력 결과의 평균을 __텐서보드에서 사용하기 위해서 디스크에 저장.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### better model\n",
    "<img src=\"./img/better.jpeg\" width=50%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### 그래프 만들기\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    ### 속성상 전역변수들인 것들 \n",
    "    with tf.name_scope(\"variables\"): \n",
    "        global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name=\"global_step\") \n",
    "        total_output = tf.Variable(0.0, dtype=tf.float32, trainable=False, name=\"global_step\")\n",
    "        # trainable=False : 변수들이 수작업으로 셋팅될것이라고 명시\n",
    "        \n",
    "    ### 핵심 연산 부분    \n",
    "    with tf.name_scope(\"transformation\"): \n",
    "        \n",
    "        # input layer\n",
    "        with tf.name_scope(\"input\"):\n",
    "            a = tf.placeholder(tf.float32, shape=[None], name=\"input_placeholder_a\")\n",
    "            \n",
    "        # middle layer\n",
    "        with tf.name_scope(\"intermediate_layer\"):\n",
    "            b = tf.reduce_prod(a, name=\"plod_b\")\n",
    "            c = tf.reduce_sum(a, name=\"sum_c\")\n",
    "            \n",
    "        # output layer\n",
    "        with tf.name_scope(\"output\"):\n",
    "            output = tf.add(b,c, name=\"output\")\n",
    "            \n",
    "            \n",
    "    ### transformation 연산을 마친후에 두개의 변수를 업데이트하는 연산\n",
    "    with tf.name_scope(\"update\"):\n",
    "        # 최근 output으로부터 total_output 변수 증가.\n",
    "        update_total = total_output.assign_add(output)\n",
    "        \n",
    "        # 그래프가 run할때마다 global_step 변수 증가.\n",
    "        increment_step = global_step.assign_add(1)\n",
    "        \n",
    "        \n",
    "    ### 텐서보드 요약\n",
    "    with tf.name_scope(\"summaries\"):\n",
    "        avg = tf.div(update_total, tf.cast(increment_step, tf.float32), name=\"average\")\n",
    "        tf.summary.scalar('Output', output)\n",
    "        tf.summary.scalar('Sum_of_outputs_over_time', update_total)\n",
    "        tf.summary.scalar('Average_of_outputs_over_time', avg)\n",
    "        \n",
    "#         tf.summary.scalar('Output', output, name=\"output_summary\")\n",
    "#         tf.summary.scalar('Sum of outputs over time', update_total, name=\"total_summary\")\n",
    "#         tf.summary.scalar('Average of outputs over time', avg, name=\"average_summary\")\n",
    "        \n",
    "    ### 변수 초기화와 모든 summary를 합치기 위한 helper node를 하나의 operation으로 만듦.\n",
    "    with tf.name_scope(\"global_ops\"):\n",
    "        # Op 초기화\n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        # 모든 summary를 하나의 operation으로 결합.\n",
    "        ## 왜 위summaries에 안넣고 여기에 놓냐? -> 전역 operation과 같이 두는 것이 일반적으로 좋은 방법. 나중에 summary가 여기저기 있더라도 여기서 관리하면 됨.\n",
    "        merged_summaries = tf.summary.merge_all()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(graph=graph)\n",
    "writer = tf.summary.FileWriter('./improved_graph', graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_graph(input_tensor):\n",
    "    feed_dict = {a: input_tensor}\n",
    "    \n",
    "    # session이 그래프를 실행. (아래 3개의 ops를 실행.)\n",
    "    _output, step, summary = sess.run([output, increment_step, merged_summaries], feed_dict=feed_dict)\n",
    "    \n",
    "    print(_output, step)\n",
    "    \n",
    "    # summary를 summarywriter에 더함.\n",
    "    writer.add_summary(summary, global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201.0 4\n"
     ]
    }
   ],
   "source": [
    "run_graph([1,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# summary를 디스트에 씀.\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer.close()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4_머신러닝 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- 지도학습 템플릿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 1. variable, model parameter 초기화\n",
    "\n",
    "### 2. training loop operation 정의\n",
    "def inference(X):\n",
    "    # 추론 모델 계산\n",
    "    pass\n",
    "\n",
    "def loss(X, Y):\n",
    "    # 예상출력과 레이블된 겂의 비교를 통해 손실 계산\n",
    "    pass\n",
    "\n",
    "def inputs():\n",
    "    # 학습 데이터 읽음\n",
    "    pass\n",
    "\n",
    "def train(total_loss):\n",
    "    # 계산된 loss에 대해 모델 파라미터를 갱신\n",
    "    pass\n",
    "        \n",
    "def evaluate(sess, X, Y):\n",
    "    # 학습된 모델을 통해 평가\n",
    "    pass\n",
    "\n",
    "### 3. 그래프 런칭\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    X, Y = inputs()\n",
    "    \n",
    "    total_loss = loss(X, Y)\n",
    "    train_op = train(total_loss)\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    # actual training loop\n",
    "    training_steps = 1000\n",
    "    \n",
    "    for step in range(training_steps):\n",
    "        sess.run([train_op])\n",
    "        if step % 10 == 0:\n",
    "            print(\"{} step // loss: {}\".format(step, sess.run([total_loss])))\n",
    "            \n",
    "    evaluate(sess, X, Y)\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 선형회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 step // loss: [54929292.0]\n",
      "10 step // loss: [14629747.0]\n",
      "20 step // loss: [7090800.0]\n",
      "30 step // loss: [5680201.0]\n",
      "40 step // loss: [5416011.0]\n",
      "50 step // loss: [5366280.0]\n",
      "60 step // loss: [5356678.0]\n",
      "70 step // loss: [5354588.0]\n",
      "80 step // loss: [5353913.5]\n",
      "90 step // loss: [5353510.0]\n",
      "[[ 313.60101318]]\n",
      "[[ 263.45443726]]\n"
     ]
    }
   ],
   "source": [
    "### 1. variable, model parameter 초기화\n",
    "W = tf.Variable(tf.zeros([2,1]), name='weights')\n",
    "b = tf.Variable(0., name='bias')\n",
    "\n",
    "\n",
    "### 2. training loop operation 정의\n",
    "def inference(X):\n",
    "    # 추론 모델 계산\n",
    "    return tf.matmul(X,W) + b\n",
    "\n",
    "def loss(X, Y):\n",
    "    # 예상출력과 레이블된 겂의 비교를 통해 손실 계산\n",
    "    Y_predicted = inference(X)\n",
    "    return tf.reduce_sum(tf.squared_difference(Y, Y_predicted))\n",
    "\n",
    "def inputs():\n",
    "    # 학습 데이터 읽음\n",
    "    weight_age = [[84, 46], [73, 20], [65, 52], [70, 30], [76, 57], [69, 25], [63, 28], [72, 36], \n",
    "                  [79, 57], [75, 44], [27, 24], [89, 31], [65, 52], [57, 23], [59, 60], [69, 48], \n",
    "                  [60, 34], [79, 51], [75, 50], [82, 34], [59, 46], [67, 23], [85, 37], [55, 40], [63, 30]]\n",
    "    \n",
    "    blood_fat_content = [354, 190, 405, 263, 451, 302, 288, 385, 402, 365, 209, 290, 346, 254, 395, \n",
    "                         434, 220, 374, 308, 220, 311, 181, 274, 303, 244]\n",
    "    return tf.to_float(weight_age), tf.to_float(blood_fat_content)\n",
    "\n",
    "def train(total_loss):\n",
    "    # 계산된 loss에 대해 모델 파라미터를 갱신\n",
    "    learning_rate = 0.00000001\n",
    "    return tf.train.GradientDescentOptimizer(learning_rate).minimize(total_loss)\n",
    "        \n",
    "def evaluate(sess, X, Y):\n",
    "    # 학습된 모델을 통해 평가\n",
    "    print(sess.run(inference([[80., 25.]])))  # ~ 303\n",
    "    print(sess.run(inference([[65., 25.]])))  # ~ 256\n",
    "\n",
    "### 3. 그래프 런칭\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    X, Y = inputs()\n",
    "    \n",
    "    total_loss = loss(X, Y)\n",
    "    train_op = train(total_loss)\n",
    "    \n",
    "    # actual training loop\n",
    "    training_steps = 100\n",
    "    \n",
    "    for step in range(training_steps):\n",
    "        sess.run([train_op])\n",
    "        if step % 10 == 0:\n",
    "            print(\"{} step // loss: {}\".format(step, sess.run([total_loss])))\n",
    "            \n",
    "    evaluate(sess, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로지스틱회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 1. variable, model parameter 초기화\n",
    "W = tf.Variable(tf.zeros([5, 1]), name=\"weights\")\n",
    "b = tf.Variable(0., name=\"bias\")\n",
    "\n",
    "### 2. training loop operation 정의\n",
    "def combine_inputs(X):\n",
    "    # 입력값을 하나로 결합.\n",
    "    # 앞에서의 inference가 입력값 결합을 위해 사용됨.\n",
    "    return tf.matmul(X, W) + b\n",
    "\n",
    "def inference(X):\n",
    "    # 추론 모델 계산\n",
    "    return tf.sigmoid(combine_inputs(X))\n",
    "\n",
    "def loss(X, Y):\n",
    "    # 예상출력과 레이블된 겂의 비교를 통해 손실 계산\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(combine_inputs(X),Y))\n",
    "\n",
    "def read_csv(batch_size, file_name, record_defaults):\n",
    "    filename_queue = tf.train.string_input_producer([os.path.join(os.getcwd(), file_name)])\n",
    "\n",
    "    reader = tf.TextLineReader(skip_header_lines=1)\n",
    "    key, value = reader.read(filename_queue)\n",
    "\n",
    "    # decode_csv will convert a Tensor from type string (the text line) in\n",
    "    # a tuple of tensor columns with the specified defaults, which also\n",
    "    # sets the data type for each column\n",
    "    decoded = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "\n",
    "    # batch actually reads the file and loads \"batch_size\" rows in a single tensor\n",
    "    return tf.train.shuffle_batch(decoded,\n",
    "                                  batch_size=batch_size,\n",
    "                                  capacity=batch_size * 50,\n",
    "                                  min_after_dequeue=batch_size)\n",
    "\n",
    "\n",
    "def inputs():\n",
    "    # 학습 데이터 읽음\n",
    "    passenger_id, survived, pclass, name, sex, age, sibsp, parch, ticket, fare, cabin, embarked = \\\n",
    "        read_csv(100, \"./data/train.csv\", [[0.0], [0.0], [0], [\"\"], [\"\"], [0.0], [0.0], [0.0], [\"\"], [0.0], [\"\"], [\"\"]])\n",
    "\n",
    "    # convert categorical data\n",
    "    is_first_class = tf.to_float(tf.equal(pclass, [1]))\n",
    "    is_second_class = tf.to_float(tf.equal(pclass, [2]))\n",
    "    is_third_class = tf.to_float(tf.equal(pclass, [3]))\n",
    "\n",
    "    gender = tf.to_float(tf.equal(sex, [\"female\"]))\n",
    "\n",
    "    # Finally we pack all the features in a single matrix;\n",
    "    # We then transpose to have a matrix with one example per row and one feature per column.\n",
    "    features = tf.transpose(tf.pack([is_first_class, is_second_class, is_third_class, gender, age]))\n",
    "    survived = tf.reshape(survived, [100, 1])\n",
    "\n",
    "    return features, survived\n",
    "\n",
    "def train(total_loss):\n",
    "    # 계산된 loss에 대해 모델 파라미터를 갱신\n",
    "    learning_rate = 0.01\n",
    "    return tf.train.GradientDescentOptimizer(learning_rate).minimize(total_loss)\n",
    "        \n",
    "def evaluate(sess, X, Y):\n",
    "    # 학습된 모델을 통해 평가\n",
    "    predicted = tf.cast(inference(X) > 0.5, tf.float32)\n",
    "    print(sess.run(tf.reduce_mean(tf.cast(tf.equal(predicted, Y), tf.float32))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 step // loss: [0.68657357]\n",
      "100 step // loss: [0.65677369]\n",
      "200 step // loss: [0.77893537]\n",
      "300 step // loss: [0.80339158]\n",
      "400 step // loss: [0.59002984]\n",
      "500 step // loss: [0.57293725]\n",
      "600 step // loss: [0.70559955]\n",
      "700 step // loss: [0.63009131]\n",
      "800 step // loss: [0.79282361]\n",
      "900 step // loss: [0.5779621]\n",
      "0.76\n"
     ]
    }
   ],
   "source": [
    "### 3. 그래프 런칭\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    X, Y = inputs()\n",
    "    \n",
    "    total_loss = loss(X, Y)\n",
    "    train_op = train(total_loss)\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    # actual training loop\n",
    "    training_steps = 1000\n",
    "    \n",
    "    for step in range(training_steps):\n",
    "        sess.run([train_op])\n",
    "        if step % 100 == 0:\n",
    "            print(\"{} step // loss: {}\".format(step, sess.run([total_loss])))\n",
    "            \n",
    "    evaluate(sess, X, Y)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
